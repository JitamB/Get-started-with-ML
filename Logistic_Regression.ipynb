{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a5f955",
   "metadata": {},
   "source": [
    "# Logistic (Softmax) Regression from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecc70d3",
   "metadata": {},
   "source": [
    "## 1. Mathematical Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f383ab9d",
   "metadata": {},
   "source": [
    "Logistic regression models the probability that an observation belongs to a particular category. \n",
    "To generate these probabilities, logistic regression uses the **sigmoid** function. This function maps a real number to a value between 0 and 1.\n",
    "\\begin{equation} \n",
    "\\sigma(z) = \\frac{1}{1+e^{-z}} --- (1)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c57fabd",
   "metadata": {},
   "source": [
    "If x is the input, $\\omega$ is the weight of each input, then weighted sum of the evidence for the class(z):\n",
    "\\begin{equation}\n",
    "z = \\sum_{i=1}^n\\omega_ix_i \\quad(taking\\space x_i = 1)\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\Rightarrow z = \\vec{\\omega} X) --- (2)\n",
    "\\end{equation}\n",
    "where $\\omega$ is a coefficient vector and X is the vector of all the observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec39495",
   "metadata": {},
   "source": [
    "So, if probability of P(y=1|x) = $\\hat{y}\\space then,\\space \\hat{y} = \\sigma(\\vec{\\omega} x)$<br>\n",
    "$\\Rightarrow$ P(y=1|x) = $\\sigma(\\vec{\\omega} x)\\quad$ --- (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87313ad6",
   "metadata": {},
   "source": [
    "For a given x, we say yes if the probability P(y = 1|x) is more than 0.5, and no otherwise. We call 0.5 the decision boundary. So, decision(x) = 1 if P(y=1|x)$\\geq$ 0.5, 0 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03333fff",
   "metadata": {},
   "source": [
    "First, we randomly allocate values to $\\omega$. Then, in each iteration (in the range of epochs) this value is systematically changed to get the final coefficient vector. The change is as follows:<br>\n",
    "<center>$\\omega_{new} = \\omega_{old} - \\eta X\\quad$ ---- (4)</center><br>\n",
    "$\\eta \\rightarrow$ Learning rate (usually between 0.0001 to 0.01)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd7c13c",
   "metadata": {},
   "source": [
    "Loss function for this model is L($\\hat{y}$, y) implies how much $\\hat{y}$ differs from the true y. This is given by:<br>\n",
    "<center>$L = \\frac{-1}{m}(y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{Y}))\\quad$ ----- (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd8d91",
   "metadata": {},
   "source": [
    "Our goal with gradient descent is to find the optimal weights: minimize the loss function weâ€™ve defined for the model. So the goal is to find the set of weights which minimizes the loss function, averaged over all examples:<br>\n",
    "<center>$\\theta_{t+1} = \\theta_t - \\eta \\nabla L(f(x;\\theta), y)\\quad$---- (6)</center><br>\n",
    "$\\theta\\rightarrow$ Parameter (weight/ bias...)<br>\n",
    "This equation is known as the cross entropy loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661408d0",
   "metadata": {},
   "source": [
    "For datasets with 3 or more categorical value or label, we use softmax regression, or multinomial regression. Here instead of sigmoid function, we use softmax function.<br>\n",
    "<center>$\\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb21811",
   "metadata": {},
   "source": [
    "## Our Model From Scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0b7db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d733d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will process the given file to execute features and target into X and y numpy array\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, filepath):\n",
    "        self.given_data = pd.read_csv(filepath) # Read the data\n",
    "        self.X, self.y = self.data_cleaning()\n",
    "\n",
    "    def data_cleaning(self): # Clean the data i.e. features and target into X and y numpy array\n",
    "        features = [col for col in self.given_data.columns if 'Feature' in col] # Feature columns are added to features\n",
    "        self.given_data = self.given_data.dropna() # drop any null value\n",
    "        data = self.given_data[features].copy()\n",
    "        data = (data - data.min()) / (data.max() - data.min()) * 9 + 1  # Scale data from 1 to 10\n",
    "        target = self.given_data['Target'].copy() # Copy the target data to target\n",
    "        X = np.array(data) # feature array\n",
    "        y = np.array(target) # target array\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4e091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is the softmax regression\n",
    "class SoftmaxRegressionFromScratch:\n",
    "    def __init__(self, X, y, lr=0.1, epochs=50000): # lr - learning rate,  epochs - no of iterations\n",
    "        self.X = self.add_intercept(X) # add bias term\n",
    "        self.y = y\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.num_classes = len(np.unique(y)) # number of classes = no of unique y value\n",
    "        self.num_features = self.X.shape[1] # number of features = row length of X\n",
    "        self.weights = np.zeros((self.num_features, self.num_classes)) # weight vector is initialized to 0 with num_feature*num_classes dimension\n",
    "        self.train() # Train the model\n",
    "\n",
    "    def add_intercept(self, X): # adds the bias term\n",
    "        intercept = np.ones((X.shape[0], 1)) # initializing the bias term\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def softmax(self, z): # softmax function\n",
    "        z -= np.max(z, axis=1, keepdims=True)  # For numerical stability\n",
    "        exp_z = np.exp(z)\n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "    # Model training\n",
    "    def train(self):\n",
    "        for _ in range(self.epochs):\n",
    "            z = np.dot(self.X, self.weights)\n",
    "            y_hat = self.softmax(z)\n",
    "            y_one_hot = self.one_hot_encode(self.y) # For more than 2 types of category each of them assigned to boolians\n",
    "            error = y_one_hot - y_hat\n",
    "            gradient = np.dot(self.X.T, error) / self.X.shape[0]\n",
    "            self.weights += self.lr * gradient\n",
    "            \n",
    "    def weight(self): # return weights\n",
    "        return self.weights\n",
    "    \n",
    "    def one_hot_encode(self, y): # For more than 2 types of category each of them assigned to boolians\n",
    "        unique_labels = np.unique(y)\n",
    "        one_hot = np.zeros((y.shape[0], unique_labels.shape[0])) # Initialized to 0\n",
    "        for i, label in enumerate(unique_labels):\n",
    "            one_hot[y == label, i] = 1 # Boolian assignment\n",
    "        return one_hot\n",
    "\n",
    "    def predict(self, X): # predict the y value from X\n",
    "        X = self.add_intercept(X) # Add bias term\n",
    "        z = np.dot(X, self.weights) # equation 2\n",
    "        y_hat = self.softmax(z) # equation 3\n",
    "        return np.argmax(y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b131ae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    @staticmethod\n",
    "    def model_accuracy(y_true, y_pred):\n",
    "        correct = np.sum(y_true == y_pred) # correct: correctly predicted y values\n",
    "        total = len(y_true)\n",
    "        accuracy = correct / total\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3356974",
   "metadata": {},
   "source": [
    "## 2 . (a) Training the scratch model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35225284",
   "metadata": {},
   "source": [
    "### [Dataset 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "962780a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "data_preprocessor1 = DataPreprocessor('data1_train.csv')\n",
    "X_train1, y_train1 = data_preprocessor1.X, data_preprocessor1.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fe204c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_model1 = SoftmaxRegressionFromScratch(X_train1, y_train1) # model initialization using train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "047f185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train1 = soft_model1.predict(X_train1) # prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bfe6035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.5%\n"
     ]
    }
   ],
   "source": [
    "score = ModelEvaluator.model_accuracy(y_train1, y_pred_train1) # evaluation\n",
    "print(f'Accuracy: {score*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892d2b92",
   "metadata": {},
   "source": [
    "### [Dataset 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a929b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data \n",
    "data_preprocessor2 = DataPreprocessor('data2_train.csv')\n",
    "X_train2, y_train2 = data_preprocessor2.X, data_preprocessor2.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c826bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_model2 = SoftmaxRegressionFromScratch(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e47766e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train2 = soft_model2.predict(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44227130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.875%\n"
     ]
    }
   ],
   "source": [
    "score = ModelEvaluator.model_accuracy(y_train2, y_pred_train2)\n",
    "print(f'Accuracy: {score*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c033e88",
   "metadata": {},
   "source": [
    "## 2. (b) Testing the scratch model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d8755",
   "metadata": {},
   "source": [
    "### [Dataset 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b15c2cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessor_test1 = DataPreprocessor('data1_test.csv')\n",
    "X_test1, y_test1 = data_preprocessor_test1.X, data_preprocessor_test1.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31261492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set: [70 70 60]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred_test1 = soft_model1.predict(X_test1)\n",
    "print(\"Predictions on test set:\", np.bincount(y_pred_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f0057b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.5%\n"
     ]
    }
   ],
   "source": [
    "score = ModelEvaluator.model_accuracy(y_test1, y_pred_test1)\n",
    "print(f'Accuracy: {score*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0aec9",
   "metadata": {},
   "source": [
    "### [Dataset 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84a68370",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessor_test2 = DataPreprocessor('data2_test.csv')\n",
    "X_test2, y_test2 = data_preprocessor_test2.X, data_preprocessor_test2.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17022b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set: [ 93 107]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test set\n",
    "y_pred_test2 = soft_model2.predict(X_test2)\n",
    "print(\"Predictions on test set:\", np.bincount(y_pred_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "920577d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.0%\n"
     ]
    }
   ],
   "source": [
    "score = ModelEvaluator.model_accuracy(y_test2, y_pred_test2)\n",
    "print(f'Accuracy: {score*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a332f5",
   "metadata": {},
   "source": [
    "## 3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0d5b79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two hyperparameter: learning rate, epochs\n",
    "class GridSearchSoftmaxRegression(SoftmaxRegressionFromScratch):\n",
    "    def __init__(self, X, y, lr=0.1, epochs=50000):\n",
    "        super().__init__(X, y, lr, epochs)\n",
    "\n",
    "    def grid_search(self, X, y, param_grid):\n",
    "        best_params = None\n",
    "        best_score = 0\n",
    "\n",
    "        for lr in param_grid['lr']: # Iterating over given learning rates\n",
    "            for epochs in param_grid['epochs']: # Iterating over given epochs\n",
    "                self.lr = lr\n",
    "                self.epochs = epochs\n",
    "                self.weights = np.zeros((self.num_features, self.num_classes))  # Reset weights\n",
    "                self.train()\n",
    "                score = self.evaluate(X, y) #evaluate score to check performance\n",
    "\n",
    "                if score > best_score: # taking the best score\n",
    "                    best_score = score\n",
    "                    best_params = {'lr': lr, 'epochs': epochs}\n",
    "\n",
    "        return best_params, best_score # got the best parameter and score at the end the nested loop\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = ModelEvaluator.model_accuracy(y, y_pred)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "087816e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid: lr - learning rate\n",
    "param_grid = {\n",
    "    'lr': [0.01, 0.05, 0.1, 0.5],\n",
    "    'epochs': [1000, 5000, 10000]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef875f5d",
   "metadata": {},
   "source": [
    "### On Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "132fb628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lr': 0.5, 'epochs': 5000}, Best Score: 97.625%\n"
     ]
    }
   ],
   "source": [
    "# search for the best parameter and value\n",
    "grid_search_model = GridSearchSoftmaxRegression(X_train1, y_train1)\n",
    "best_params1, best_score1 = grid_search_model.grid_search(X_train1, y_train1, param_grid)\n",
    "print(f\"Best Parameters: {best_params1}, Best Score: {best_score1*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6de22be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a model using the best value to compare accuracy\n",
    "best_model1 = GridSearchSoftmaxRegression(X_train1, y_train1, lr=best_params1['lr'], epochs=best_params1['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89fcaf1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set: [70 70 60]\n",
      "Accuracy: 96.5%\n"
     ]
    }
   ],
   "source": [
    "tuned_y_pred1 = best_model1.predict(X_test1)\n",
    "print(\"Predictions on test set:\", np.bincount(tuned_y_pred1))\n",
    "score = ModelEvaluator.model_accuracy(y_test1, tuned_y_pred1)\n",
    "print(f'Accuracy: {score*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5838c4ef",
   "metadata": {},
   "source": [
    "### On Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5c367c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'lr': 0.1, 'epochs': 10000}, Best Score: 99.0%\n"
     ]
    }
   ],
   "source": [
    "grid_search_model = GridSearchSoftmaxRegression(X_train2, y_train2)\n",
    "best_params2, best_score2 = grid_search_model.grid_search(X_train2, y_train2, param_grid)\n",
    "print(f\"Best Parameters: {best_params2}, Best Score: {best_score2*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf434960",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model2 = GridSearchSoftmaxRegression(X_train2, y_train2, lr=best_params2['lr'], epochs=best_params2['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3eb2232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set: [ 94 106]\n",
      "Accuracy: 93.5%\n"
     ]
    }
   ],
   "source": [
    "tuned_y_pred2 = best_model2.predict(X_test2)\n",
    "print(\"Predictions on test set:\", np.bincount(tuned_y_pred2))\n",
    "score = ModelEvaluator.model_accuracy(y_test2, tuned_y_pred2)\n",
    "print(f'Accuracy: {score*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ababbe4",
   "metadata": {},
   "source": [
    "## 4. Comparision with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39a63168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # Logistic regression from scikit learn\n",
    "\n",
    "class SkLearnLogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression() # Define the model\n",
    "    \n",
    "    def train(self, X_train, y_train): # Train the model using model.fit() function \n",
    "        self.model.fit(X_train, y_train)\n",
    "    \n",
    "    def predict(self, X_test): # Predict the model output using model.predict() function \n",
    "        return self.model.predict(X_test)\n",
    "    \n",
    "    def evaluate_accuracy(self, y_true, y_pred): # evaluate the model\n",
    "        self.accuracy = accuracy_score(y_true, y_pred)\n",
    "        return self.accuracy      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "890346a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model = SkLearnLogisticRegression() # Initialize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f41f40",
   "metadata": {},
   "source": [
    "### - On Dataset 1 (train & test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa71d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model.train(X_train1, y_train1) # Train the model using train1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee02c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sk_pred1 = sklearn_model.predict(X_test1) # predict y/target value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7bc0d6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.5%\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score\n",
    "score = sklearn_model.evaluate_accuracy(y_test1, y_sk_pred1)\n",
    "print(f'Accuracy: {score*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4df941",
   "metadata": {},
   "source": [
    "### - On Dataset 2 (train & test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "524907ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as previous but with train2 dataset\n",
    "sklearn_model.train(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5879df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.5%\n"
     ]
    }
   ],
   "source": [
    "y_sk_pred2 = sklearn_model.predict(X_test2)\n",
    "score = sklearn_model.evaluate_accuracy(y_test2, y_sk_pred2)\n",
    "print(f'Accuracy: {score*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29bf60a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
